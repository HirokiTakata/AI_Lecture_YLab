{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTrww-rcaX-6"
   },
   "source": [
    "# 基盤人工知能演習 第7回\n",
    "\n",
    "※本演習資料の二次配布・再配布はお断り致します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TASDvDe6nnTm"
   },
   "source": [
    "　今回の演習資料は以下の2つのテーマが記載されている。\n",
    "\n",
    "　**AI7.1 | 畳み込みニューラルネットワーク (CNN)**\n",
    "\n",
    "　**AI7.2 | 再帰型ニューラルネットワーク (RNN)**\n",
    "\n",
    "　なお、時間の都合上、本日の授業時間内では**AI7.1 | 畳み込みニューラルネットワーク (CNN)** のみを取り扱い、再帰型ニューラルネットワークは資料のみ配布する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvn85rDMveId"
   },
   "source": [
    "## AI7.1 | 畳み込みニューラルネットワーク (Convolutional Neural Network; CNN) \n",
    "\n",
    "　CNNを使わない画像ベースの学習手法は無いのではないか？というレベルに広く用いられている手法である。前回の演習でも利用したMNISTの分類予測を行うことで、CNNがどのくらい強力か見てみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1mwvyaCKr-E"
   },
   "source": [
    "### AI7.1.1 | CNNの構成要素のおさらい\n",
    "\n",
    "　2次元のCNNは`torch.nn.Conv2d(16, 32, kernel_size=(5, 5), padding=2, stride=2)`のように定義するのだが、見てわかるようにこれまでの`torch.nn.Linear(512, 512)`に比べると設定すべきパラメータが多い。\n",
    "これから自分が組むニューラルネットワークがどのような計算を行っているかを理解することは大切なので、講義でも習った要素を今一度確認しよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uS61VC8g1fR1"
   },
   "source": [
    "#### 畳み込み演算\n",
    "　画像処理における「畳み込み」という操作は、**図AI7.1**のように、入力行列 $f$ とフィルタ $g$ を入力として、**フィルタの適用範囲を平行移動させながら $f$ と $g$ の積和を計算していく処理**であり、一般的には **$f*g$** と記述する。なお、後述のパディングを行わない限り出力の画像サイズは入力の画像サイズよりも小さくなることに注意しよう。\n",
    "\n",
    "　この演算において、学習する重み $w$ はどこにあるだろうか。**フィルタ $g$ の各要素が学習によって最適化される重み**である。\n",
    "\n",
    "![図AI7.1](https://i.imgur.com/GTQj9dH.png)\n",
    "\n",
    "**図AI7.1 | 畳み込み演算**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ry3S-jFQKvQB"
   },
   "source": [
    "#### 入力チャネル数と出力チャネル数\n",
    "\n",
    "　最も単純なCNNは各ピクセルごとに1つの値が存在するデータを処理する例である。これは、グレースケールの画像（例えばこれまでやってきたMNIST）を入力とする時などが考えられる。\n",
    "一方、例えばカラーの画像はRGB (Red, Green, Blue) の3つのデータが各ピクセルに与えられており、これは**3チャネルの入力**ということができる。この場合は、**図AI7.2**のように1つの出力値を作るために3倍の計算を行う必要がある。\n",
    "\n",
    "　さらに、フィルタを複数用意することで出力チャネル数も複数にすることができる。例えば、**図AI7.3**は**入力チャネル数が3、出力チャネル数が2**であるようなCNNの例になっている。\n",
    "\n",
    "　`torch.nn.Conv2d(16, 32, kernel_size=(5, 5), padding=2, stride=2)`のうち、16と32の数値がそれぞれ入力/出力チャネル数である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dfn1OyEK9wU"
   },
   "source": [
    "\n",
    "\n",
    "![図AI7.2](https://i.imgur.com/y3t7aw6.png)\n",
    "\n",
    "**図AI7.2 | 複数の入力チャネルが存在するCNN** 基盤人工知能 第7回 講義資料より抜粋・一部改変\n",
    "\n",
    "![図AI7.3](https://i.imgur.com/mBXnaEY.png)\n",
    "\n",
    "**図AI7.3 | 入力チャネルと出力チャネルが複数であるCNN** 基盤人工知能 第7回 講義資料より抜粋・一部改変\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NhKYsppNKvF_"
   },
   "source": [
    "#### フィルタサイズ（カーネルサイズ）\n",
    "　`torch.nn.Conv2d(16, 32, kernel_size=(5, 5), padding=2, stride=2)` の**`kernel_size=(5,5)`**で与えている情報、これがフィルタサイズ（あるいはカーネルサイズ）である。フィルタサイズは1つの値を出力するための**積和計算を行う範囲を示す値**で、例えば`(2,2)`であれば合計4ピクセルについて、入力データとフィルタとの積和を計算することになる（前述の**図AI7.1**の例はフィルタサイズが2×2となっている）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wnIN_iaOKu9D"
   },
   "source": [
    "#### パディング\n",
    "\n",
    "　`torch.nn.Conv2d(16, 32, kernel_size=(5, 5), padding=2, stride=2)` の **`padding=2`** がパディングである。\n",
    "パディングが無いと前述のように出力の画像サイズが小さくなってしまう。それを防ぐために、周囲を0で埋めることがしばしば行われる。これがパディングである（**図AI7.4**）。フィルタサイズの1辺が $2k+1$ であるとき、パディングを $k$ とすることで、入力の画像サイズと出力の画像サイズが等しくなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbqptYQrLByw"
   },
   "source": [
    "![図AI7.4](https://i.imgur.com/s2IWPpB.png)\n",
    "\n",
    "**図AI7.4 | パディングが存在するCNN** 基盤人工知能 第7回 講義資料より抜粋・一部改変"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_yjEywdK137"
   },
   "source": [
    "#### ストライド\n",
    "\n",
    "　かなり大きな画像に対して学習を行う場合、サイズの圧縮を狙って数ピクセルに1回だけ畳み込みを行うことがある。これがストライドであり、**`stride=2`**がそれにあたる（**図AI7.5**）。\n",
    "\n",
    "　ただ、通常はストライドを増やすより、後述のMaxPoolingを利用するのが一般的である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uWjl9BpqKZl"
   },
   "source": [
    "![図AI7.5](https://i.imgur.com/FYKrN2A.png)\n",
    "\n",
    "**図AI7.5 | ストライドが2であるCNN** 基盤人工知能 第7回 講義資料より抜粋・一部改変\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1K8sdQ7zqeG-"
   },
   "source": [
    "### AI7.1.2 | Max pooling（プーリング層）\n",
    "\n",
    "　次に、CNNと併せて用いられることが多いmax pooling（プーリング層）について簡単に説明する。Pooling層は複数のピクセルを1つの値にまとめる操作を行うもので、最大値を取るmax poolingが通常用いられる。これにより、わずかな画像の平行移動があっても予測に影響しにくくなると言われている。\n",
    "**図AI7.6**を見てわかるように、画像の1辺が1/2, 1/3の単位で小さくなるので、非常に大きな画像を学習する場合にはより大きなストライド幅のプーリング層を用いたり、多数のプーリング層を導入したりする。\n",
    "\n",
    "　PyTorchでは、`torch.nn.MaxPool2d(2)`とすることで、ストライド2の二次元max poolingを行うことができる。\n",
    "\n",
    "![図AI7.6](https://i.imgur.com/kUH7lra.png)\n",
    "\n",
    "**図AI7.6 | Max Poolingの例** 基盤人工知能 第7回 講義資料より抜粋・一部改変"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6iQHo9S7xGeK"
   },
   "source": [
    "### AI7.1.3 | Flatten\n",
    "\n",
    "　最後に、2次元状に並んだデータを（これまで学習に利用していたような）1次元の配列に直す `torch.nn.Flatten()` について述べておく。 **`Flatten()` とは、図7.7のように、2次元（以上）のデータを1次元に変換する操作のこと**である。CNNを用いる学習では、最後の数層は`Linear()`層を用いることが多いため、2次元空間のピクセル様のデータから、これまで取り扱ってきた1次元のベクトルに変換する操作が必要になる。**CNN系の層とこれまで用いてきた層をつなぐ役割を果たしている**と考えればよいだろう。\n",
    "\n",
    "![図 AI7.7](https://i.imgur.com/FAwNc0x.png)\n",
    "\n",
    "**図 AI7.7 | Flattenの例** 複数チャネル存在している場合でも、1次元のベクトルに変換する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDasRg4JYQo0"
   },
   "source": [
    "-----\n",
    "##### 課題 AI7.1\n",
    "\n",
    "　入力画像が 2チャネル×縦10ピクセル×横12ピクセル である時、\n",
    "`torch.nn.MaxPool2d(2)` によって得られる出力次元を答えよ。\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmlCor-UqjrX"
   },
   "source": [
    "### AI7.1.4 | CNNを用いたMNISTの分類予測\n",
    "\n",
    "　それでは、ここまでで説明してきたCNN, max pooling, flattenを利用して、手書き数字MNISTを学習してみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVH8Gdpzptn_"
   },
   "source": [
    "　まずは、前回と同様にlivelosplotを用いるためのインストールを行う。Google Colabはクラウドサービスのため、毎回不足しているパッケージをインストールしたり、あるいはデータを作る必要があるので注意しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fttHiJ3_p7Ts"
   },
   "outputs": [],
   "source": [
    "# 以下のコマンドはPythonのコマンドではなく、Google Colabだから実行可能\n",
    "# pipというPythonのパッケージ管理ツールを使ってlivelossplotをインストールしている\n",
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYBb4u-sqCSX"
   },
   "source": [
    "　次に、MNISTデータの準備を行う。\n",
    "$X$の作成以外は前回と同じコードになっている。\n",
    "$X$は、**1チャネル（モノクロ画像）×縦28ピクセル×横28ピクセル**のデータとして準備を行うため、\n",
    " `X_train` などは (データ数,1,28,28) の4階テンソルに整形する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9YVvEWUWxJj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testset  = torchvision.datasets.MNIST(root=\".\", train=False, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZb3g0dqXPU6"
   },
   "outputs": [],
   "source": [
    "# torch.tensor -> numpy.array\n",
    "X_train = trainset.data.numpy()\n",
    "y_train = trainset.targets.numpy()\n",
    "X_test = testset.data.numpy()\n",
    "y_test = testset.targets.numpy()\n",
    "\n",
    "# scaled from [0,255] to [0,1] for X\n",
    "X_train = X_train / 255\n",
    "X_test  = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TfKwNFhjMGf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# trainを50000件のtrainingデータと10000件のvalidationデータに分割する\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
    "                                                      train_size=50000, random_state=0)\n",
    "\n",
    "# testはそのまま利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrYc9g--YG1S"
   },
   "outputs": [],
   "source": [
    "# ここが変更点\n",
    "# 1チャネル×縦28ピクセル×横28ピクセル\n",
    "X_train_fig = X_train.reshape(50000, 1, 28, 28) \n",
    "X_valid_fig = X_valid.reshape(10000, 1, 28, 28)\n",
    "X_test_fig  = X_test.reshape(10000, 1, 28, 28) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aHDkhYwp9ct"
   },
   "source": [
    "　あとは、いつもと同様に `torch.tensor` に変換させて、 DataLoader まで作ってしまおう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7RbfgJyqV2l"
   },
   "outputs": [],
   "source": [
    "batch_size = 256 # 今回は256件のデータごとに学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rs3P-_DgqMB-"
   },
   "outputs": [],
   "source": [
    "# training set\n",
    "X_train_torch = torch.tensor(X_train_fig, dtype=torch.float) # dtype=torch.floatを忘れずに\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.long)      # dtype=torch.longを忘れずに\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_torch, y_train_torch)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gE9lmA3eqam3"
   },
   "outputs": [],
   "source": [
    "# validation set\n",
    "X_valid_torch = torch.tensor(X_valid_fig, dtype=torch.float)\n",
    "y_valid_torch = torch.tensor(y_valid, dtype=torch.long)\n",
    "valid_dataset = torch.utils.data.TensorDataset(X_valid_torch, y_valid_torch)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQ3vWuiuql2R"
   },
   "outputs": [],
   "source": [
    "# test set\n",
    "X_test_torch = torch.tensor(X_test_fig, dtype=torch.float)\n",
    "y_test_torch = torch.tensor(y_test, dtype=torch.long)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_torch, y_test_torch)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKfXEmiurGZb"
   },
   "source": [
    "　続いて、前回と同様にGPUの利用設定や、学習および予測のための関数群を定義する。前回の演習時のコードと全く変わらない。DataLoaderを使えるモデルであれば汎用的に使えるように関数は整備したので、実際の用途にも応用できるはずである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmXiSJULrLgP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "device_GPU = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEBBpnwmriWq"
   },
   "outputs": [],
   "source": [
    "def update_model(model, loss_fn, opt, train_loader, device):\n",
    "  train_loss = 0\n",
    "  train_correct = 0\n",
    "  train_count = len(train_loader.dataset)\n",
    "  \n",
    "  for X, y in train_loader:\n",
    "    X = X.to(device) # GPUへデータを転送\n",
    "    y = y.to(device) # GPUへデータを転送\n",
    "    y_pred = model(X) # Xからyを予測\n",
    "    \n",
    "    _, predicted = torch.max(y_pred.data, 1) # 予測された10クラスの確率のうち、確率が最大だったものを得る\n",
    "    train_correct += (predicted == y).sum().item() # 予測に成功した件数をカウント（accuracy計算用）\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)        # ミニバッチ内の訓練誤差の 平均 を計算\n",
    "    train_loss += loss.item()*len(y) # エポック全体の訓練誤差の 合計 を計算しておく\n",
    "    \n",
    "    # 重みの更新\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "  # エポック内の訓練誤差の平均値と予測精度を計算\n",
    "  mean_train_loss = train_loss / train_count\n",
    "  train_accuracy = train_correct / train_count\n",
    "  \n",
    "  return mean_train_loss, train_accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swRqYOte6Zmz"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, loss_fn, dataloader, device):\n",
    "  model.eval() # 学習を行わない時は evaluate 状態にする （補足資料※1）\n",
    "\n",
    "  valid_loss = 0\n",
    "  valid_correct = 0\n",
    "  valid_count = len(dataloader.dataset)\n",
    "\n",
    "  for X, y in dataloader:\n",
    "    X = X.to(device) # GPUへ転送\n",
    "    y = y.to(device) # GPUへ転送\n",
    "    y_pred = model(X) # Xからyを予測\n",
    "    \n",
    "    _, predicted = torch.max(y_pred.data, 1) # 予測された10クラスの確率のうち、確率が最大だったものを得る\n",
    "    valid_correct += (predicted == y).sum().item() # 予測に成功した件数をカウント（accuracy計算用）\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)        # ミニバッチ内の訓練誤差の 平均 を計算\n",
    "    valid_loss += loss.item()*len(y) # エポック全体の訓練誤差の 合計 を計算しておく\n",
    "    \n",
    "  mean_valid_loss = valid_loss / valid_count\n",
    "  valid_accuracy = valid_correct / valid_count\n",
    "\n",
    "  model.train() # evaluate状態からtrain状態に戻しておく\n",
    "  return mean_valid_loss, valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtwUoAWB6aga"
   },
   "outputs": [],
   "source": [
    "def train(model, loss_fn, opt, train_loader, valid_loader, device, epoch=50):\n",
    "  liveloss = PlotLosses()\n",
    "  for i in range(epoch):\n",
    "    train_loss, train_accuracy = update_model(model, loss_fn, opt, train_loader, device)\n",
    "    valid_loss, valid_accuracy = evaluate_model(model, loss_fn, valid_loader, device)\n",
    "  \n",
    "    # Visualize the loss and accuracy values.\n",
    "    liveloss.update({\n",
    "        'log loss': train_loss,\n",
    "        'val_log loss': valid_loss,\n",
    "        'accuracy': train_accuracy,\n",
    "        'val_accuracy': valid_accuracy,\n",
    "    })\n",
    "    liveloss.draw()  \n",
    "  print('Accuracy: {:.4f} (valid), {:.4f} (train)'.format(valid_accuracy, train_accuracy))\n",
    "  return model # 学習したモデルを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IBQmduRrpJ4"
   },
   "source": [
    "　それでは、CNN＋LinearによるMNIST予測モデルを構築し、学習を行ってみよう。今回は `Conv2d()` を1回行うごとに `MaxPool2d()` で画像サイズを2分の1にしているが、複数回 `Conv2d()` をしてから`MaxPool2d`をすることもある（時間があれば、基盤人工知能 第7回 講義で紹介したAlexNetのネットワーク構造を見てみると良い）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXAmhoMOrxUj"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # 学習結果の再現性を担保\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "cnn = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 16, (5, 5)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(16, 32, (5, 5)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),    \n",
    "    torch.nn.Flatten(), \n",
    "    torch.nn.Linear(32*4*4, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10),\n",
    ")\n",
    "cnn.to(device_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKIoi7roqeX5"
   },
   "source": [
    "　上記のCNNの定義のコードの中には**入力画像サイズ（縦横28ピクセルずつ）が明示的に記述されていない**ことに注意してほしい。上記のモデルの各段階で画像データがどのような変遷をたどるか、**図AI7.8**に図解しておくので、こちらも併せてみておくと良いだろう。\n",
    "\n",
    "\n",
    "![図 AI7.8](https://i.imgur.com/GfxYmY0.png)\n",
    "\n",
    "**図 AI7.8 | 今回構築したネットワーク** 画像状の構造をしているデータは常に正方であるため、画像幅とチャネル数のみ値を記している。また、簡略化の為に活性化関数は直前の層と併せて記述した。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnUYB8bYsKMw"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # 学習結果の再現性を担保\n",
    "\n",
    "# 誤差関数と最適化手法を準備\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.1)\n",
    "\n",
    "# 学習の実行\n",
    "trained_model = train(cnn, loss_fn, optimizer, train_loader, valid_loader, device_GPU)\n",
    "\n",
    "# 予測の実行\n",
    "test_loss, test_accuracy = evaluate_model(cnn, loss_fn, test_loader, device_GPU)\n",
    "print(test_loss)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTTLFRbMrAEV"
   },
   "source": [
    "　先ほどは、至極当然のようにmodelを作成したが、各層の入力サイズ・出力サイズを意識しながらモデルを構築することは案外難しい。`Flatten`の直前では**32チャネル×縦4マス×横4マス**になっている、ということは、一瞬見ただけではなかなか理解ができない。\n",
    "\n",
    "　このような場合、torchsummaryというライブラリを用いることで、簡単に各層の出力サイズを見ることができる。実際に利用してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfQ9eft7tU_e"
   },
   "outputs": [],
   "source": [
    "# Flattenまでを抜き出した途中までのモデル\n",
    "cnn_part = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 16, (5, 5)),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, (5, 5)),\n",
    "    torch.nn.MaxPool2d(2),    \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten()\n",
    ")\n",
    "cnn_part.to(device_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cTft95PSKFE"
   },
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(cnn_part, (1, 28, 28)) # ミニバッチを除いた入力の形状（チャネル数、縦横サイズ）を入力する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q27O-_sOSS2C"
   },
   "source": [
    "　このように、入力が1チャネル×縦28マス×横28マスだった場合の各層の出力サイズが表示され、Flattenの出力が512次元であることがわかる（図AI7.8と見比べてみよ）。Flattenの次のLinear層の入力次元数は512とすればよいようだ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMyeAgWBu0PA"
   },
   "source": [
    "----\n",
    "##### 課題 AI7.2\n",
    "\n",
    "　間違ったモデルを組んだ状態で学習をさせようとするとどうなるだろうか。\n",
    "予測まで行う説明で使ったモデルの最初の`Conv2d()`を`torch.nn.Conv2d(1, 16, (5, 5), padding=2)`とすることで（誤った）モデルを構成し、`train()`を実行せよ。この時、どのようなエラーが発生するだろうか。エラーメッセージを報告し、メッセージの内容を簡単に説明せよ（ヒント：`torch.addmm`とはどういう関数か？）。\n",
    "\n",
    "\n",
    "```\n",
    "cnn = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 16, (5, 5)), # ここを書き換えることで誤ったモデルを作成する\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, (5, 5)),\n",
    "    torch.nn.MaxPool2d(2),    \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(), \n",
    "    torch.nn.Linear(32*4*4, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 10),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VuKdGMKRv5LO"
   },
   "source": [
    "------\n",
    "##### 課題 AI7.3\n",
    "\n",
    "　課題 AI7.2におけるエラーメッセージを参考に`torch.nn.Flatten()`直後の`torch.nn.Linear()`の入力次元数を修正することで、`train()`を行ってもエラーが発生せずに学習を行えるモデルを作成せよ。\n",
    "\n",
    "演習の解答としては、`torch.nn.Linear(____, 256)` の下線部を埋めよ。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVXSyielsSBq"
   },
   "source": [
    "-----\n",
    "##### 課題 AI7.4 **（授業後に修正あり）**\n",
    "\n",
    "　課題 AI7.3で実装したモデルについて学習を実施せよ。レポートには以下のことを記せ。\n",
    "\n",
    "1. 50エポック終了時のモデルの訓練データ、検証データ、テストデータに対する正解率\n",
    "2. 説明に用いたモデルと課題 AI7.3のモデルは、どちらの方が性能が良かったか。\n",
    "\n",
    "なお、この課題を行う際には、演習資料のコードと同様に、モデルの定義と学習の実行の前にそれぞれ `torch.manual_seed(0)` を~行い、 複数回実行しても実験結果が一致していることを確認せよ~行え。\n",
    "\n",
    "（1/23補足情報：もしGPUを使ってでも結果を固定したい場合は、学習前に `torch.backends.cudnn.deterministic = True` とコードを記述すると良い。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oA_WsUvsChJU"
   },
   "source": [
    "----\n",
    "##### 課題 AI7.5（発展）\n",
    "\n",
    "　研究において、「他人が再現実験が行えること」は非常に重要な要素である。\n",
    "CNNモデルを自由に組み立て、学習を行った上で、テストデータの予測正解率を報告せよ。ただし、**採点者が全く同じ結果を得るために必要な情報を付与**せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7AfhkqPcPEBD"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zyqUDabxoOu"
   },
   "source": [
    "## AI7.2 | 再帰型ニューラルネットワーク (Recurrent Neural Network)\n",
    "\n",
    "　**※ この節は授業では取り扱いません。各自実行してみてください。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JJgeBisCtMQ"
   },
   "source": [
    "　RNN（Recurrent Neural Network、再帰型ニューラルネットワーク）は時系列データに対する逐次的な予測や、可変長のデータに対する単一の予測を行う際に利用できるニューラルネットワークの1手法である。\n",
    "\n",
    "　近年ではRNNを発展させたLSTM-RNN (Long-Short term memory recurrent neural network)などが広く使われてはいるが、ここでは、最も基礎的なRNNを、実際に可変長のデータに対する予測問題を解くために利用してみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZgFJqV6T4At"
   },
   "source": [
    "### AI7.2.1 | データの準備：苗字から言語圏を予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6b0IlQorCLd4"
   },
   "source": [
    "　苗字のローマ字表記から、どの言語圏の苗字なのかを予測することを考える。\n",
    "当然苗字は可変長なので、これについてもRNNなどの手法を用いることが妥当であろう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOQ6dF7-CgWY"
   },
   "source": [
    "　とりあえず、データを準備する（これはPyTorch公式のtutorialから取得している）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bg5UQ01liJho"
   },
   "outputs": [],
   "source": [
    "!wget https://download.pytorch.org/tutorial/data.zip\n",
    "!unzip -o data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-HpjpmoDOgp"
   },
   "source": [
    "　いつものようにデータの中身を見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kldNto0NLyOb"
   },
   "outputs": [],
   "source": [
    "!head -n10 data/names/Japanese.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54p-dWwRiWmK"
   },
   "source": [
    "#### RNNが理解できる表現への変換\n",
    "\n",
    "　これまでと同様、深層学習自体は数値的な表現がされたデータしか学習や予測に用いることはできない。文字列は扱いに困るので、これをまず数値列に変換しよう。\n",
    "\n",
    "　以下は苗字の文字列を数値列に変換するコードである（が、ここでは詳しくは説明しない。öをoに変換するなど、特殊な記号を排除した上で、苗字の文字列を`'A'->3, 'b'->30`といったように、文字と数値が1対1対応するように変換している）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6sFMmTmiT3T"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "# Alphabet [a-zA-Z .,;']\n",
    "alphabet = set(string.ascii_letters + \" .,;'\")\n",
    "\n",
    "def normalize(s):\n",
    "    # Apply canonical decomposition, and ignore non-alphabet symbols.\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s) if c in alphabet\n",
    "        )\n",
    "# normalize('Ślusàrski') -> 'Slusarski'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKWUzGxur0r6"
   },
   "outputs": [],
   "source": [
    "def build_char_mapping(surnames):\n",
    "  characters = set()\n",
    "  for surname in surnames:\n",
    "    surname = normalize(surname)\n",
    "    characters.update(list(surname))\n",
    "  characters = sorted(characters)\n",
    "  \n",
    "  char_map = {}\n",
    "  for i, char in enumerate(characters):\n",
    "    char_map.setdefault(char, i)\n",
    "  return char_map\n",
    "\n",
    "def build_lang_mapping(languages):\n",
    "  langs = set(languages)\n",
    "  langs = sorted(langs)\n",
    "  \n",
    "  lang_map = {}\n",
    "  for i, lang in enumerate(langs):\n",
    "    lang_map.setdefault(lang, i)\n",
    "  return lang_map\n",
    "\n",
    "\n",
    "def convert_surnames(surnames, charmap):\n",
    "  X = []\n",
    "  for surname in surnames:\n",
    "    chars_surname = list(surname)\n",
    "    X.append([charmap[c] for c in chars_surname])\n",
    "  return X\n",
    "\n",
    "def convert_languages(languages, langmap):\n",
    "  y = [langmap[s] for s in languages]\n",
    "  return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXaZaoa_z2Qc"
   },
   "source": [
    "　さらに、18種類の言語圏を18種類のクラスラベル（数値）に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIaHroYFXtDv"
   },
   "outputs": [],
   "source": [
    "surnames = []\n",
    "languages = []\n",
    "srcs = glob.glob('data/names/*.txt')\n",
    "srcs = sorted(srcs)\n",
    "for src in srcs:\n",
    "  lang = os.path.basename(src)[:-4]\n",
    "  for line in open(src):\n",
    "    line = line.strip('\\n')\n",
    "    surnames.append(normalize(line))\n",
    "    languages.append(lang)\n",
    "\n",
    "charmap = build_char_mapping(surnames)\n",
    "langmap = build_lang_mapping(languages)\n",
    "\n",
    "np.savez_compressed(\n",
    "    'surname-language',\n",
    "    charmap = charmap,\n",
    "    langmap = langmap,\n",
    "    surname = convert_surnames(surnames, charmap),\n",
    "    language = convert_languages(languages, langmap)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VB1PvUOJZ1BU"
   },
   "source": [
    "　以上のコードで、苗字と言語圏をそれぞれ数値化したデータが完成した。\n",
    "データの中身を見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LfbrFR2Mzlk"
   },
   "outputs": [],
   "source": [
    "data = np.load('surname-language.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEhOTdqSaoQD"
   },
   "outputs": [],
   "source": [
    "data[\"surname\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gt9pwWYoa00b"
   },
   "outputs": [],
   "source": [
    "X = data[\"surname\"]\n",
    "y = data[\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8tOwBy7bEtv"
   },
   "outputs": [],
   "source": [
    "i = 9500\n",
    "print(X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmYFu906Z_OZ"
   },
   "source": [
    "　どうやら6文字の苗字のようだが・・・、人間には理解できなくなってしまった。復元してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErsaR2YsaZLs"
   },
   "outputs": [],
   "source": [
    "# 復元用のdictデータの作成\n",
    "rev_charmap = {} \n",
    "for key, value in charmap.items():\n",
    "  rev_charmap[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DVwzOqxawDN"
   },
   "outputs": [],
   "source": [
    "i = 9500\n",
    "print([rev_charmap[idx] for idx in data[\"surname\"][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bg70ee2uZzzc"
   },
   "source": [
    "　`Ochiai`さんが`[17, 31, 36, 37, 29, 37]`という名前に変換されていたようだ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Se7lgDkNhfin"
   },
   "source": [
    "　そうしたら、いつものようにtorch.tensor化して、dataset, dataloaderを作成…したいのだが、**可変長な入力のままではDataLoaderを使うことができない。**今回は、DataLoaderを利用することをあきらめて、学習時に適宜処理することにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfqrXvw1ViMt"
   },
   "source": [
    "### AI7.2.2 | RNNを含んだモデルの構築と学習の実施"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgGTyToQ-0av"
   },
   "source": [
    "　次に、RNNを含んだモデルを構築するのだが、RNNを含んだモデル構築は多少技術が必要である。\n",
    "というのも、一般的には**RNNは入力が与えられるたびに出力を行うモデル**である（**図 AI7.9**）ため、今回のように**文字列に対して1つの出力を得たい場合**には、**RNNの最後の出力のみを取り出して利用する**必要がある。\n",
    "\n",
    "　このような仕組みは、これまで利用してきた`torch.nn.Sequential()`だけでは表現できず、自作する必要がある。\n",
    "\n",
    "\n",
    "![図 AI7.9](https://i.imgur.com/M88oTpB.png)\n",
    "\n",
    "**図 AI7.9 | RNNの模式図** 逐次的にデータが入力され、そのたびに出力が行われる。出力 $h$ は入力 $x$ だけではなく、それまでの入力列にも影響される。 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqhPOYHdb7Ke"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 最後の出力だけを次の層に渡すRNN\n",
    "class lastoutputRNN(torch.nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super(lastoutputRNN, self).__init__() # 初期化のおまじない\n",
    "    \n",
    "    # 学習すべき重みがあるものをここに全て定義\n",
    "    self.rnn = torch.nn.RNN(input_size, output_size, num_layers=1)\n",
    "  \n",
    "  # 予測時の計算を定義\n",
    "  def forward(self, input):\n",
    "    outs_rnn, hiddens = self.rnn(input, self.initHidden()) # ひとまず複数の 出力 h を全て受け取る\n",
    "    last_out_rnn = outs_rnn[-1] # 最後の出力 h_r を抜き出す\n",
    "    return last_out_rnn # 次の層に渡す\n",
    "\n",
    "  # RNNの隠れ層の初期値を準備する補助関数\n",
    "  def initHidden(self):\n",
    "    return torch.zeros(1, 1, self.rnn.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljNuw3rreKVT"
   },
   "source": [
    "　以上で用意した、RNNの最後の出力だけを出力する層を用いて、学習を行ってみよう（6分半程度かかるので、以下を実行してからコードを理解すると良い）。他人のコードを読むことは慣れている人間でもそれなりに時間がかかるので、落ち着いて理解していこう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07kA2h6dyj4o"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from livelossplot import PlotLosses # livelossplotのインストールを忘れずに（AI7.1.4参照）\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0) # 実行結果を再現させる\n",
    "np.random.seed(0)    # data_shuffle()のためにNumPyの乱数も指定する\n",
    "\n",
    "\n",
    "###### Sequentialによるモデルの作成\n",
    "# 入力：文字列のone-hot表現\n",
    "# 出力：入力の文字列が「どの言語らしいか」を示す値（各言語ごとに実数値を出力）\n",
    "model = torch.nn.Sequential(\n",
    "    lastoutputRNN(len(charmap), 128), \n",
    "    torch.nn.Linear(128, len(langmap))\n",
    ")\n",
    "    \n",
    "###### 入力・出力のPyTorch用データへの変換を行う関数\n",
    "def x_to_tensor(x, input_size): # one hot encodingを行っている\n",
    "    tensor = torch.zeros(len(x), 1, input_size, dtype=torch.float)\n",
    "    for i, j in enumerate(x):\n",
    "        tensor[i][0][j] = 1   # tensor.shape = (T, batch, input_dim)\n",
    "    return tensor\n",
    "def y_to_tensor(y):\n",
    "    return torch.tensor([y], dtype=torch.long)\n",
    "  \n",
    "  \n",
    "###### データをランダムに並び替える関数\n",
    "# Xとyの対応関係を損なわないために、インデックスをshuffleして\n",
    "# それに基づいてX, yを同時に並び変える、ということを行っている\n",
    "def data_shuffle(X, y):\n",
    "  indices = list(range(len(X)))\n",
    "  np.random.shuffle(indices)\n",
    "  X = X[indices]\n",
    "  y = y[indices]\n",
    "  return X, y\n",
    "\n",
    "###### 入力 X と教師信号（期待される出力）y の読み込み\n",
    "data = np.load('surname-language.npz', allow_pickle=True)\n",
    "charmap = data[\"charmap\"].item()\n",
    "langmap = data[\"langmap\"].item()\n",
    "X = data[\"surname\"]\n",
    "y = data[\"language\"]\n",
    "\n",
    "###### 誤差関数と最適化手法の定義\n",
    "# これはいつもと同じ\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "###### 学習本体\n",
    "liveloss = PlotLosses() # 描画の準備\n",
    "\n",
    "for epoch in range(10): # 10 epoch 学習する\n",
    "    total_train_loss = 0.0\n",
    "    num_train_correct = 0\n",
    "    X, y = data_shuffle(X, y)\n",
    "    \n",
    "    # Training loop for every instance.\n",
    "    for Xi, yi in zip(X, y):\n",
    "      # X, y からそれぞれ1つずつデータを取得する\n",
    "\n",
    "        # 数値列データを逐次torch.tensorに変換\n",
    "        Xi_torch = x_to_tensor(Xi, len(charmap))\n",
    "        yi_torch = y_to_tensor(yi)\n",
    "\n",
    "        # 予測の実施\n",
    "        y_pred = model(Xi_torch) \n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        num_train_correct += (predicted == yi_torch).sum().item()\n",
    "        \n",
    "        # 予測の誤差を計算（交差エントロピー誤差）\n",
    "        loss = loss_fn(y_pred, yi_torch)\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # 誤差逆伝播法による重みの更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # このepoch全体での予測精度 (accuracy) を計算\n",
    "    train_accuracy = num_train_correct / len(y)\n",
    "\n",
    "    # livelossplotの描画\n",
    "    liveloss.update({\n",
    "        'log loss': total_train_loss,\n",
    "        'accuracy': train_accuracy,\n",
    "    })\n",
    "    liveloss.draw()\n",
    "    \n",
    "# 最後のepochにおける訓練データの予測精度を出力\n",
    "print('Accuracy: {:.4f} (train)'.format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cS_lvN2H-pzO"
   },
   "source": [
    "　このモデルを使うことで、15以上の言語圏の苗字を訓練データに対する予測精度で75%程度の正答率で予測することができた。学習曲線を見る限り、まだ精度は向上しそうである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FySTSqlACKlZ"
   },
   "source": [
    "　最後に、このモデルを使って、`Masu`さんと`Sato`さんはどの言語圏の苗字かを予測してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kIx2GAUC61Q"
   },
   "outputs": [],
   "source": [
    "new_surnames = [\"Masu\", \"Sato\"]\n",
    "new_surnames = convert_surnames(new_surnames, charmap)  # 数値列化\n",
    "for surname in new_surnames:\n",
    "  x_torch = x_to_tensor(surname, len(charmap))\n",
    "  pred = model(x_torch)                                 # 予測の実施\n",
    "  _, predicted = torch.max(pred.data, 1)                # 最も確率の高かったクラスを求める\n",
    "  print(predicted)                                      # 予測されたクラスを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOa5PiLjD5lN"
   },
   "source": [
    "　いずれもクラス10であると予測された。langmapを見ればクラス10はどの言語かがわかるので確認してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpaTAEcUDvZp"
   },
   "outputs": [],
   "source": [
    "print(langmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiupaUEvEA4o"
   },
   "source": [
    "　どうやら、正しく日本語の苗字だと認識したようだ（お分かりかと思うが、`Masu`は現在の東工大の学長の苗字である）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeDGFhtj_GB0"
   },
   "source": [
    "------\n",
    "##### 課題 AI7.6（発展、提出の必要はありません）\n",
    "\n",
    "　このモデルをデータセットにない苗字に適用することを考える。その時の予測精度はどの程度であると予想されるか。以下の3択から選択し、その理由を簡単に述べよ。\n",
    "\n",
    "1. 75%より高い精度で予測できると考えられる\n",
    "2. 75%程度の精度で予測できると考えられる\n",
    "3. 75%未満の精度で予測できると考えられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRqUkc16F5md"
   },
   "source": [
    "-----\n",
    "##### 課題 AI7.7（極めて発展、提出の必要はありません）\n",
    "　`lastoutputRNN`クラスやモデルを適切に書き換えることで、苗字の途中まで読んだ時点での言語予想を出力させることができる。しかし、途中経過の予測結果が学習に影響を及ぼすのは好ましいことではない。そこで、**学習には影響させず、予測時のみ途中での言語予想を出力させる**ようなクラスおよびモデルを完成させよ。`Gotoh`（後藤）という苗字の言語予想がどのように変化していくか確認せよ。\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37DMY818jzZy"
   },
   "source": [
    "# レポート提出について\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLzUiGyLXOdo"
   },
   "source": [
    "## レポートの提出方法\n",
    "　レポートは**答案テンプレートを用い**、**1つのファイル (.doc, .docx, .pdf)** にまとめ、**学籍番号と氏名を確認の上**、**1/30 15:00 (次回 基盤人工知能演習) までに東工大ポータルのOCW-iから提出**すること。\n",
    "ファイルのアップロード後、OCW-iで「提出済」というアイコンが表示されていることを必ず確認すること。それ以外の場合は未提出扱いとなるので十分注意すること。\n",
    "また、締め切りを過ぎるとファイルの提出ができないため、時間に余裕を持って提出を行うこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQbnf5fNmccL"
   },
   "source": [
    "### 答案テンプレート\n",
    "\n",
    "```\n",
    "学籍番号:\n",
    "名前:\n",
    "\n",
    "課題 AI7.1\n",
    " ____ チャネル × 縦 ____ ピクセル × 横 ____ ピクセル\n",
    "\n",
    "課題 AI7.2\n",
    "エラーメッセージ：\n",
    "エラーの内容説明：\n",
    "\n",
    "課題 AI7.3\n",
    "torch.nn.Linear(____, 256)\n",
    "\n",
    "課題 AI7.4\n",
    "訓練データに対する正解率：\n",
    "検証データに対する正解率：\n",
    "テストデータに対する正解率：\n",
    "より良いモデルはどちらか：\n",
    "\n",
    "課題 AI7.5\n",
    "（自由記述）\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AI7_ConvolutionalNN_and_RecurrentNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
